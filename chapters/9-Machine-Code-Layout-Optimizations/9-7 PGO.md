---
typora-root-url: ..\..\img
---

## Profile Guided Optimizations {#sec:secPGO}	

Compiling a program and generating optimal assembly listing is all about heuristics. Code transformation algorithms have many corner cases that aim for optimal performance in specific situations. For a lot of decisions that compiler makes, it tries to guess the best choice based on some typical cases. For example, when deciding whether a particular function should be inlined, the compiler could take into account the number of times this function will be called. The problem is that compiler doesn't know that beforehand.

Here is when profiling information becomes handy. Given profiling information compiler can make better optimization decisions. There is a set of transformations in most compilers that can adjust their algorithms based on profiling data fed back to them. This set of transformations is called Profile Guided Optimizations (PGO). Sometimes in literature, one can find the term Feedback Directed Optimizations (FDO), which essentially refers to the same thing as PGO. Often times a compiler will rely on profiling data when it is available. Otherwise, it will fall back to using its standard algorithms and heuristics. 

It is not uncommon to see real workloads performance increase by up to 15% from using Profile Guided Optimizations. PGO does not only improve inlining and code placement but also improves register allocation[^6]and more. 

Profiling data can be generated based on two different ways: code instrumentation (see [@sec:secInstrumentation]) and sample-based profiling (see [@sec:profiling]). Both are relatively easy to use and have associated benefits and drawbacks discussed in [@sec:secApproachesSummary].

The first method can be utilized in the LLVM compiler by building the program with the `-fprofile-instr-generate` option. This will instruct the compiler to instrument the code, which will collect profiling information at runtime. After that LLVM compiler can consume profiling data with the `-fprofile-instr-use` option to recompile the program and output PGO-tuned binary. The guide for using PGO in clang is described in the [documentation](https://clang.llvm.org/docs/UsersManual.html#profiling-with-instrumentation)[^7]. GCC compiler uses different set of options `-fprofile-generate` and `-fprofile-use` as described in GCC [documentation](https://gcc.gnu.org/onlinedocs/gcc/Optimize-Options.html#Optimize-Options).

The second method, which is generating profiling data input for the compiler based on sampling, can be utilized thanks to [AutoFDO](https://github.com/google/autofdo)[^8] tool, which converts sampling data generated by Linux `perf` into a format that compilers like GCC and LLVM can understand. [@AutoFDO]

Keep in mind that the compiler "blindly" uses the profile data you provided. The compiler assumes that all the workloads will behave the same, so it optimizes your app just for that single workload. Users of PGO should be careful about choosing the workload to profile because while improving one use case of the application, other might be pessimized. Luckily, it doesn't have to be exactly a single workload since profile data from different workloads can be merged together to represent a set of use cases for the application.

In the mid-2018, Facebook open-sourced its binary relinker tool called [BOLT](https://code.fb.com/data-infrastructure/accelerate-large-scale-applications-with-bolt/). BOLT works on the already compiled binary. It first disassembles the code, then it uses profile information to do various layout transformations (including basic blocks reordering, function splitting, and grouping) and generates optimized binary [@BOLT]. A similar tool was developed at Google called [Propeller](https://github.com/google/llvm-propeller/blob/plo-dev/Propeller_RFC.pdf), which serves a similar purpose as BOLT but claim certain advantages over it. It is possible to integrate optimizing relinker into the build system and enjoy an extra 5-10% performance speedup from the optimized code layout. The only thing one needs to worry about is to have a representative and meaningful workload for collecting profiling information. 

[^6]: because with PGO compiler can put all the hot variables into registers, etc.
[^7]: PGO in Clang - [https://clang.llvm.org/docs/UsersManual.html#profiling-with-instrumentation](https://clang.llvm.org/docs/UsersManual.html#profiling-with-instrumentation).
[^8]: AutoFDO - [https://github.com/google/autofdo](https://github.com/google/autofdo).
