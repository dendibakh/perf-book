## Questions and Exercises {.unlisted .unnumbered}

1. Is it safe to take an average time over a series of measurements?
2. Suppose you've identified a performance bug that you're now trying to fix in your development environemtn. How you would reduce the noise in the system to have more pronounced benchmarking results.
3. Is it OK to track overall performance of a program with function-level unittests?
4. Does your organization has performance regression system in place? If yes, can it be improved? If no, think about the strategy of installing one. Take into consideration: what is changing and what isn't (source code, compiler, HW config, etc), how often a change occurs, what is the measurement variance, what is the running time of the benchmark and how many iterations you can run?