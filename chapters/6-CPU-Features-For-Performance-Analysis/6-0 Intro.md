---
typora-root-url: ..\..\img
---

# CPU Features for Performance Analysis {#sec:PmuChapter}

The ultimate goal of performance analysis is to identify performance bottlenecks and locate parts of the code that are associated with them. Unfortunately, there are no predetermined steps to follow, so it can be approached in many different ways. 

Usually, profiling an application can give quick insights about the hotspots of the application. Sometimes it is everything developers need to do to fix performance inefficiencies. Especially high-level performance problems can often be revealed by profiling. For example, consider a situation when you've just made a change to the function `foo` in your application and suddenly see a noticeable performance degradation. So, you decide to profile the application. According to your mental model of the application, you expect that `foo` is a cold function and it doesn't show up in the top-10 list of hot functions. But when you open the profile, you see it consumes a lot more time than before. You quickly realize the mistake you've made in the code and fix it. If all issues in performance engineering were that easy to fix, this book would not exist.

When you embark on a journey to squeeze the last bit of performance from your application, the most basic list of hotspots is not enough. Unless you have a crystal ball or an accurate model of an entire CPU in your head, you need additional support to understand what the performance bottlenecks are. However, before using the information presented in this chapter, make sure that the application you are trying to optimize does not suffer from major performance flaws. Because if it does, using CPU performance monitoring features for low-level tuning doesn't make sense. It will likely steer you in the wrong direction, and instead of fixing real high-level performance problems, you will be tuning bad code, which is just a waste of time.

Some developers rely on their intuition and proceed with random experiments, trying to force various compiler optimizations like loop unrolling, vectorization, inlining, you name it. Indeed, sometimes you can be lucky and enjoy a portion of compliments from your colleagues and maybe even claim an unofficial title of performance guru on your team. But usually, you need to have a very good intuition and luck. In this book we don't teach you how to be lucky. Instead, we show methods that have proved to be working in practice.

Modern CPUs are constantly getting new features that enhance performance analysis in different ways. Using those features greatly simplifies finding low-level issues like cache-misses, branch mispredictions, etc. In this chapter, we will take a look at a few HW performance monitoring capabilities available on modern CPUs. Processors from different vendors do not necessarily have the same set of features. In this chapter, we will focus on performance monitoring capabilities available in Intel, AMD, and ARM processors. RISC-V ecosystem does not yet have a mature performance monitoring infrastructure, so we will not cover it here.

* **Top-down Microarchitecture Analysis** (TMA) methodology, discussed in [@sec:TMA]. This is a powerful technique for identifying ineffective usage of CPU microarchitecture by a program. It characterizes the bottleneck of a workload and allows locating the exact place in the source code where it occurs. It abstracts away intricacies of the CPU microarchitecture and is relatively easy to use even for inexperienced developers.
* **Last Branch Record** (LBR), discussed in [@sec:lbr]. This is a mechanism that continuously logs the most recent branch outcomes in parallel with executing the program. It is used for collecting call stacks, identify hot branches, calculating misprediction rates of individual branches, and more.
* **Processor Event-Based Sampling** (PEBS), discussed in [@sec:secPEBS]. This is a feature that enhances sampling. Its primary benefits include: lowering the overhead of sampling; and providing "Precise Events" capability, that enables pinpointing of the exact instruction that caused a particular performance event.
* **Intel Processor Traces** (PT), discussed in Appendix D. It is a facility to record and reconstruct the program execution with a timestamp on *every* instruction. Its main usages are postmortem analysis and root-causing performance glitches.

The Intel PT feature is covered in Appendix D. Intel PT was supposed to be an "end game" for performance analysis. With its low runtime overhead, it is a very powerful analysis feature. But it turns out to be not very popular among performance engineers. Partially because the support in the tools is not mature, partially because in many cases it is an overkill, and it's just easier to use a sampling profiler. Also, it produces a lot of data, which is not practical for long-running workloads.

The features mentioned above provide insights on the efficiency of a program from the CPU perspective. In the next chapter we will discuss how profiling tools leverage them to provide many different types of performance analysis.
