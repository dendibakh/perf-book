## System Tuning {#sec:SysTune}

After completing all the hard work of tuning an application to exploit all the intricate facilities of the CPU microarchitecture, the last thing we want is for the system firmware, the OS, or the kernel to destroy all our efforts. The most highly tuned application will mean very little if it is intermittently disrupted by a system interrupt that halts the entire system from executing firmware code. Such interrupt might run for up to tens to hundreds of milliseconds at a time.

Fair to say, that developers usually have little to no control over the environment in which the application is executed. When we ship the product, it's unrealistic to tune every setup a customer might have. Usually, large enough organizations have separate Operations Teams (Ops), which handle such sort of issues. Nevertheless, when communicating with members of such teams, it's important to understand what else can limit the application to show its best performance.

There are many things to tune in a modern system, and avoiding system-based interference is not an easy task. An example of a performance tuning manual of x86-based server deployments is Red Hat [guidelines](https://access.redhat.com/sites/default/files/attachments/201501-perf-brief-low-latency-tuning-rhel7-v2.1.pdf)[^5]. There, you will find tips for eliminating or significantly minimizing cache-disrupting interrupts from sources like the system BIOS, the Linux kernel, and from device drivers, among many other sources of application interference. These guidelines should serve as a baseline image for all new server builds before any application is deployed into a production environment.

When it comes to tuning a specific system setting, it is not always an easy 'yes' or 'no' answer. For example, it's not clear upfront whether your application will benefit from the Simultaneous Multi-Threading (SMT) feature enabled in the environment in which your software is running. The general guideline is to enable SMT only for heterogeneous workloads[^6] that exhibit a relatively low IPC. On the other hand, CPU manufacturers these days offer processors with such high core counts that SMT is far less necessary than it was in the past. However, this is just a general guideline, and as with everything stressed so far in this book, it is best to measure for yourself.

Most out-of-the-box platforms are configured for optimal throughput while saving power when it's possible. But there are industries with real-time requirements, which care more about having lower latency than everything else. An example of such an industry can be robots operating in automotive assembly lines. Actions performed by such robots are triggered by external events and usually have a predetermined time budget to finish because the next interrupt will come shortly (it is usually called a "control loop"). Meeting real-time goals for such a platform may require sacrificing the overall throughput of the machine or allowing it to consume more energy. One of the popular techniques in that area is to disable processor sleeping states[^7] to keep it ready to react immediately. Another interesting approach is called Cache Locking,[^8] where portions of the CPU cache are reserved for a particular set of data; it helps to streamline the memory latencies within an application.

A more extreme shot at boosting performance is to overclock the CPU. Overclocking is a process of running the CPU at a higher frequency than it was designed for. It is a risky operation, as it can void the warranty and potentially damage the CPU. Overclocking is not suited for production environments and is usually done by enthusiasts who are willing to take the risk for the sake of performance. To overclock a CPU, you need to have the right parts, mainly a motherboard that supports overclocking, a CPU that is unlocked, and a cooling system that can handle the increased heat output. At the beginning of 2024, overclocking experts crossed the 9 GHz barrier on a widely available CPU.[^9]

[TODO]: Make a connection to the next case study about LLC sensitivity.

[^5]: Red Hat low latency tuning guidelines - [https://access.redhat.com/sites/default/files/attachments/201501-perf-brief-low-latency-tuning-rhel7-v2.1.pdf](https://access.redhat.com/sites/default/files/attachments/201501-perf-brief-low-latency-tuning-rhel7-v2.1.pdf)
[^6]: I.e., when sibling threads execute differing instruction patterns.
[^7]: Power Management States: P-States, C-States - [https://software.intel.com/content/www/us/en/develop/articles/power-management-states-p-states-c-states-and-package-c-states.html](https://software.intel.com/content/www/us/en/develop/articles/power-management-states-p-states-c-states-and-package-c-states.html)
[^8]: Cache Locking. Survey of cache locking techniques [@CacheLocking]. An example of pseudo-locking a portion of the cache, which is then exposed as a character device in the Linux file system and made available for `mmap`ing: [https://events19.linuxfoundation.org/wp-content/uploads/2017/11/Introducing-Cache-Pseudo-Locking-to-Reduce-Memory-Access-Latency-Reinette-Chatre-Intel.pdf](https://events19.linuxfoundation.org/wp-content/uploads/2017/11/Introducing-Cache-Pseudo-Locking-to-Reduce-Memory-Access-Latency-Reinette-Chatre-Intel.pdf)
[^9]: CPU overclocking records - [https://press.asus.com/news/press-releases/rog-maximus-z790-apex-encore-sets-3-overclocking-world-records/](https://press.asus.com/news/press-releases/rog-maximus-z790-apex-encore-sets-3-overclocking-world-records/)