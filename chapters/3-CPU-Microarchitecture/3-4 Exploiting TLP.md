## Exploiting Thread Level Parallelism

Techniques described previously rely on the available parallelism in a program to speed up execution. In addition, CPUs support techniques to exploit parallelism across processes and/or threads executing on the CPU. A hardware multi-threaded CPU supports dedicated hardware resources to track the state (aka context) of each thread independently in the CPU instead of tracking the state for only a single executing thread or process. The main motivation for such a multi-threaded CPU is to switch from one context to another with the smallest latency (without incurring the cost of saving and restoring thread context) when a thread is blocked due to a long latency activity such as memory references.  

### Simultaneous Multithreading

Modern CPUs combine ILP techniques and multi-threading by supporting simultaneous multi-threading to eke out the most efficiency from the available hardware resources. Instructions from multiple threads execute concurrently in the same cycle. Dispatching instructions simultaneously from multiple threads increases the probability of utilizing the available superscalar resources, improving the overall performance of the CPU. In order to support SMT, the CPU must replicate hardware to store the thread state (program counter, registers). Resources to track OOO and speculative execution can either be replicated or partitioned across threads. Typically cache resources are dynamically shared amongst the hardware threads. Modern multi-threaded CPUs  support either two threads (SMT2) or four threads (SMT4).